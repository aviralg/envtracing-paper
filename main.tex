\documentclass[10pt,review,sigplan,anonymous=true,authorversion=true,nonacm=true]{acmart}
\settopmatter{printfolios=false,printccs=false,printacmref=false}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}   %% For author/year citations
\usepackage{listings,multirow,wrapfig,xspace,paralist}
\usepackage{xcolor,tikz,graphicx, pifont}
%\usetikzlibrary{positioning}

%% \newcommand{\authorcomment}[3]{\xspace\textcolor{#1}{{\bf #2} #3}\xspace}
\newcommand{\authorcomment}[3]{}
% For author notes:
\newcommand{\AG}[1]{\authorcomment{orange}{AG}{#1}}
\newcommand{\JV}[1]{\authorcomment{red}{JV}{#1}}

% For meta comments:
\newcommand{\isit}[1]{\authorcomment{cyan}{Check}{#1}}
\newcommand{\todo}[1]{\authorcomment{red}{TODO}{#1}}
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}
\newcommand{\cmark}{\textcolor{green}{\ding{51}}}

\definecolor{LightGray}{RGB}{247, 247, 247}
\definecolor{Gray}{rgb}{.3,.3,.3}
\definecolor{DarkGray}{rgb}{.5,.5,.5}

%% https://www.davehofmann.de/defining-custom-language-templates-for-latex-listings/
% Define Language
\lstdefinelanguage{smalleR} {
  % list of keywords
  morekeywords={
    for,
    if,
    else,
    function
  },
  sensitive=true, % keywords are not case-sensitive
  morecomment=[l]{\#}, % l is for line comment
  morestring=[b]{"} % defines that strings are enclosed in double quotes
}

\lstset{
  language={smalleR},
  columns=flexible,
  captionpos=b,
  frame=single,
  framerule=0pt,
  framexleftmargin=1mm,
  framexrightmargin=1mm,
  tabsize=2,
  belowskip=0pt,
  basicstyle=\small\ttfamily,
  backgroundcolor=\color{LightGray},
  emphstyle=\sffamily,
  keywordstyle=\bfseries,
  commentstyle=\color{Gray}\em,
  stringstyle=\color{Gray},
  alsoletter={., _, $},
  breaklines=true
}

\newcommand{\code}[1]{\lstinline |#1|\xspace}
\renewcommand{\c}[1]{\lstinline |#1|\xspace}
\newcommand{\eg}{\emph{e.g.},\xspace}
\newcommand{\ie}{\emph{i.e.},\xspace}

\newcommand{\environmentFun}{\code{environment}}
\newcommand{\asEnvironment}{\code{as.environment}}

\newcommand{\emptyenv}{\code{empyenv}}
\newcommand{\globalenv}{\code{globalenv}}

\newcommand{\base}{\code{base}}
\newcommand{\methods}{\code{methods}}
\newcommand{\lazyLoadDBexec}{\code{lazyLoadDBexec}}

\newcommand{\newEnv}{\code{new.env}}

\newcommand{\asList}{\code{as.list}}
\newcommand{\listToEnv}{\code{list2env}}

\newcommand{\ls}{\code{ls}}
\newcommand{\objects}{\code{objects}}

\newcommand{\subDollar}{\code{$}}
\newcommand{\subBracket}{\code{[[}}

\newcommand{\exist}{\code{exist}}

\newcommand{\get}{\code{get}}
\newcommand{\getZero}{\code{get0}}
\newcommand{\mget}{\code{mget}}
\newcommand{\dynGet}{\code{dynGet}}

\newcommand{\assign}{\code{assign}}

\newcommand{\remove}{\code{remove}}
\renewcommand{\rm}{\code{rm}}

\newcommand{\lockEnvironment}{\code{lockEnvironment}}
\newcommand{\lockBinding}{\code{lockBinding}}
\newcommand{\unlockBinding}{\code{unlockBinding}}

\newcommand{\eval}{\code{eval}}
\newcommand{\substitute}{\code{substitute}}

\newcommand{\parentEnv}{\code{parent.env}}
\newcommand{\parentEnvAssign}{\code{parent.env<-}}

\newcommand{\envtracer}{{\sf envtracer}\xspace}
\newcommand{\experimentr}{{\sf experimentr}\xspace}
\newcommand{\rdyntrace}{{\sf R-dyntrace}\xspace}

\newcommand{\ggplot}{\textit{ggplot2}\xspace}
\newcommand{\vctrs}{\textit{vctrs}\xspace}

%%% \setcopyright{rightsretained}
%%% \acmPrice{}
%%% \acmDOI{10.1145/3360579}
%%% \acmYear{2019}
%%% \copyrightyear{2019}
%%% \acmJournal{PACMPL}
%%% \acmVolume{3}
%%% \acmNumber{OOPSLA}
%% \acmArticle{153}
%%% \acmMonth{10}
\begin{document}
\title{On Design and Use of First-Class Environments in R}

\author{Aviral Goel}\affiliation{\institution{Northeastern University}\country{USA}}
\author{Jan Vitek}\affiliation{\institution{Czech Technical University and Northeastern University}\country{USA}}
\authorsaddresses{}
\renewcommand{\shortauthors}{Goel, et al.}


\begin{abstract}
  The R programming language is widely used for statistical computing. To enable
  interactive data exploration and rapid prototyping, R encourages a dynamic
  programming style. This programming style is support by a number of features
  including first-class environments. R is the only language, with millions of
  users, that provides a full reflective interface for manipulating
  environments. With the great flexibility afforded by first-class environments,
  comes challenges for reasoning about code and significant restrictions about
  what transformations a compiler is allowed to apply to programs. This paper is
  an overview of the environment interface refined over two decades. We explain
  the rationale behind the design and document how environments are used in the
  wild by the means of a corpus analysis.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002944.10011123.10010912</concept_id>
<concept_desc>General and reference~Empirical studies</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011050.10010517</concept_id>
<concept_desc>Software and its engineering~Scripting languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011039.10011311</concept_id>
<concept_desc>Software and its engineering~Semantics</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{General and reference~Empirical studies}
\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[500]{Software and its engineering~Scripting languages}
\ccsdesc[300]{Software and its engineering~Semantics}

%\keywords{R language, delayed or lazy evaluation}

\maketitle
\section{Introduction}

The ability to name values in a computation is a key building block of
linguistic abstractions. Programming languages have concepts such as local
variables, global variables, function parameters that boil down to a mapping
values to names, commonly referred to as an \emph{environment}. The semantics of
environments have a profound impact on how programming languages can be
implemented. At a first approximation, restricted semantics greatly simplify the
task of generating efficient machine code.

Early languages had variables that were read and written to by statically
determined names, and they did not support recursive functions. Thus there was a
single environment for compilation unit and, in that environment, each variable
its own memory location; as it generated code the compiler knew exactly which
location every name referred to. When a variable's value was constant, that
variable could be treated as a synonym for its value and did not require a
memory location. To improve performance, variables could be cached in machine
registered and spilled to memory only when needed.

As languages became more expressive, allowing recursion and first-class
functions, implementations had to allocate environments, respectively, on the
stack or in the heap. Lisp treated code as data, and thus lifted the restriction
that variable names be statically known. This meant that from a compiler's point
of view, it became much harder to generate efficient code. Environments were
data structures that could at any time be inspected and the mapping between
variables and values be observed.

In this paper we focus on the R programming language created in 1993~\cite{r96}, as
a directed descendent to S whose origin dates to 1976~\cite{s88}. Inspired by Lisp,
CLOS, and Scheme, the designers of R created a lazy functional language that
supported various forms of object-oriented programming. One of the keys to
expressivity was the choice of making environments first-class. Environments are
data structures that can be created and manipulated programmatically. One can,
for example, write code that acquires the environment of the caller of the
currently executing function, check if it contains a variable named \c{x}, and,
if it does, rename that variable to \c{y}. Needless to say that this flexibility
does limit what a compiler can do make R run fast~\cite{dls19}.

Our goal with this paper is to document the interface that R exposes to
environments. This interface evolved through the years, some of it dates back to
S, with changes and adaptations through the decades. The interface is rich and
not always consistent or certainly not minimal. Through a dynamic analysis
conducted on a corpus of popular R libraries and their clients, we report on the
practical usage of environments. This allows us to explain the need for this
rich interface and could, possibly, be a step towards a re-design or a hint for
compiler writers as to where optimization opportunities may lie.

\section{Related Work}

\paragraph{Contemporary Languages} The Scheme Standard~\cite{SchemeR5RS}
requires implementations to support \code{eval} whose second argument is an
\emph{environment-specifier}, not required to be a first-class environment. The
effect of assignment to bound variables in this environment is unspecified,
leaving open the possibility of it being immutable. MIT/GNU Scheme supports
first-class environments, and as a consequence, its \code{eval} takes an
explicit environment as its second argument. This Scheme provides functions to
create new environments, read and write bindings, examine parent environments,
and obtain the current environment as a reified value. Python provides the
\code{locals} function that returns the local bindings as a dictionary, attached
to the current frame as the \code{f_locals} attribute. Updates to this
dictionary are not reflected in the function's scope, unlike R. Caller's
bindings can be accessed by looking up \code{f_locals} from their frames,
obtained from \code{inspect.stack}. Calling \code{locals} outside of a function
returns the namespace as a dictionary at the point and changes to this
dictionary are reflected in the namespace. Similar to R's \code{globalenv},
Python's \code{globals} returns a dictionary of the global namespace whose
updates are also reflected in the namespace.

\paragraph{Supporting First-Class Environments} \citet{NishizakiSTLC94}
introduced a simply typed lambda calculus with first-class environments, proved
that it is strongly normalizing, and proposed a type inference algorithm.
\citet{NishizakiML94} proposed a sound type inference algorithm for a type
system with ML-polymorphism in a $\lambda$-calculus with first-class
environments.

\paragraph{The R language} \citet{ecoop12} evaluated the design of R, providing
a comprehensive explanation of R's scoping and evaluation mechanism. They
present many aspects of environments in the context of laziness,
metaprogramming, dynamic evaluation, explicit environment manipulation, and call
stack inspection, but they don't discuss explicit environment creation using
\code{new.env}. In comparison to their work, our work focuses only on
environments and provides a much more detailed qualitative and quantitative
account. Furthermore, our study shows a significantly larger and richer use of
explicit environments in the R ecosystem compared to theirs. \citet{oopsla19b}
studied the design and use of laziness in R. They provide a detailed account of
the languageâ€™s evaluation strategy with a small-step operational semantics and
an empirical evaluation of laziness in 16,707 packages. Their semantics shows
that promises are stored in environments and can outlive the frame that created
them if returned as part of that environment. \citet{oopsla20b} inferred type
signatures for R functions by observing the type of argument and return values.
Their type language includes a designated \textbf{\texttt{env}} type for
first-class environments.


\section{Environments in the R Language}

R is a vectorized, dynamic, lazy, functional and object-oriented programming
language, designed by Ihaka and Gentleman in 1993 as a successor to S. In this
section, we provide a brief primer on R, with a focus on environments.

R has first-class, anonymous, lexically scoped functions. They are the most
important linguistic construct; all expressions (bracketing, operators, etc.)
desugar to function calls.

Vectors in R are homogeneous fixed-size arrays of integer, double, character
(string), logical (boolean), complex, or raw (byte) values. Lists are
heterogeneous vectors with optionally named elements. They can be indexed by
position or name. R objects can be tagged with user-defined data called
attributes. They are an optional name value map typically used to add a
domain-specific type structure. For example, \code{attr(x, dim) <- c(2, 2))}
attaches the attribute \code{dim} to vector \code{x<-c(1,2,3,4)} and R
subsequently treats it as a 2$\times$2 matrix. Of special interest is the
\code{class} attribute. \code{class(x)<-c("cat","animal")} sets the class of
\code{x} to \code{"cat"} and \code{"animal"}. This is used for object-oriented
programming by S3 and S4, two OOP frameworks of R. S3 uses the \code{class}
attribute to dispatch on the first argument, and S4 allows multiple dispatch.
Formula is a compact symbolic representation of models used by model fitting
functions. For example, the linear model \code{y ~ x-1} specifies a line through
the origin. Formula contains a reference to the environment in which it is
defined to refer to the variables, if they are not otherwise provided during
model fitting.

Environments bind names to values. They are backed either by an association list
(default) or a hash table, chosen on initialization. Unlike other R objects,
they are modified by reference. Environments form a chain; each environment
points to a parent environment. The chain terminates at the \code{empty}
environment; which is always empty. The call, \code{emptyenv()}, returns the
\code{empty} environment.

\subsection{Environments as Packages}

Packages loaded by calling \code{library} are represented as environments; their
names are added to a global search path (returned by \code{search()}) for
lookup. The \code{n}th package environment can be retrieved using
\code{pos.to.env(n)}, or \code{as.environment(n)}. \asEnvironment also accepts
the package name as its argument. Every package has a corresponding namespace
environment which also contains its private bindings and implementation specific
metadata. The namespace environment for a package named \code{ns} can be
obtained by calling \code{getNamespace(ns)}. An R session starts with the
\code{base} package preloaded, which contains the default R APIs.
\code{baseenv()} returns the \code{base} package environment and
\code{.BaseNamespaceEnv} is bound to the \code{base} package namespace.

\subsection{Environments as Scopes}
The top-level scope is the \code{global} environment, referred by the variable
\code{.GlobalEnv}, or returned by \code{globalenv()}. The \code{environment()}
call returns the current evaluation environment which is either the
\code{global} environment or the current function's environment. When supplied
with a function argument, it returns the function's definition environment.
\code{environment(fun) <- env} sets \code{env} as the environment of \code{fun}.

\begin{lstlisting}
 f <- function() print(environment())
 environment(); environment(f); f()
 # <env: Global> <env: Global> <env: 0x7ff>
 e <- new.env()
 print(e)
 # <env: 0x7f1>
 environment(f) <- e
 environment(f)
 # <env: 0x7f1>
\end{lstlisting}

\noindent
R provides a call stack reflection interface. Frame number starts from 0, for
\code{global} environment (top level), and increases by 1 for each nested call.
\code{sys.nframe()} returns the current frame number. \code{sys.parent(n)}
returns the frame number of the \code{n}th parent. The function
\code{sys.frame(n)} returns the environment of the frame at position \code{n}
(counting backwards if \code{n} is negative). Function \code{parent.frame(n)} is
an optimized implementation of \code{sys.frame(sys.parent(n))}. Lastly,
\code{sys.frames()} returns a list of all active frames' environments.

\begin{lstlisting}
 f <- function() { print(environment())
 g <- function() { parent.frame(1) }; g() }
 f()
 # <env: 0x7f2> <env: 0x7f2>
\end{lstlisting}

\subsection{Environments as Data Structures}
Environments can be created using the \newEnv function. This function takes
three arguments: \code{hash}, a boolean for selecting a hash table
representation over the default association list representation, \code{size}, a
number specifying the size for preallocation, and, \code{parent}, the enclosing
environment. R does not provide any function to query the representation used
for an environment.The \code{length} function of an environment (number of
bindings) can be obtained using the. \parentEnv yields the enclosing environment
of an environment and \code{parent.env(envir) <- parent} sets the enclosing
environment of \code{envir} to \code{parent}.

\begin{lstlisting}
  e <- new.env(parent=emptyenv())
  length(e)
  # 0
  parent.env(e)
  # <environment: R_EmptyEnv>
  parent.env(e) <- globalenv()
  parent.env(e)
  # <environment: R_GlobalEnv>
\end{lstlisting}

\asList converts environments to lists, heterogeneous vectors with optionally
named elements. \listToEnv copies the elements of a list to an environment. If
the environment is not supplied, it creates one using \newEnv. The variables of
an environment can be retrieved as a vector using the \ls and \objects
functions.

\begin{lstlisting}
  l <- list(x=1, y=2); e <- list2env(l)
  length(e)
  # 2
  as.list(e)
  # list(y = 2, x = 1)
  ls(e)
  # [1] "x" "y"
\end{lstlisting}

A variable's existence in an environment can be queried using \exist. Its value
can be retrieved using \subDollar and \subBracket operators. \get, \getZero,
\mget, and \dynGet functions are generalizations of these operators with options
to perform lookup recursively in parent environments (\code{inherits = TRUE})
and validate the type of value bound to the variable being read (\code{mode =
  "integer"}). \getZero is \get with an extra argument, \code{ifnotfound}, which
is returned if the variable is not present in the environment. \mget is a
vectorized version of \get; it reads multiples variables supplied as a vector
and returns a vector of values. \dynGet performs recursive lookups in caller
frames, i.e., dynamic scopes, unlike the other functions which perform lookup in
lexical scopes.

Writes can be performed in an environment using the \assign function. Operator
forms, \code{env$var <- val}, and \code{env[["var"]] <- val}, can also be used
for mutating variable \code{var} in environment \code{env}. Bindings
can be removed from an environment using the \rm and \remove function.

An environment can be protected from addition or removal of bindings by locking
it with \lockEnvironment. This does not protect existing bindings from
modification, which can be explicitly locked using \lockBinding. A locked
binding can be removed if the environment is not locked. Bindings can be
unlocked using \unlockBinding.

Expressions can be evaluated explicitly in an environment using the \eval
function. To support metaprogramming, R provides the \substitute function. This
function extracts the unevaluated argument text from the promise bound to the
argument in the supplied environment.


\paragraph{Discussion.} R provides a large API for interactive with environments
and accessing scopes as explicit environments. Environments in R are very
versatile objects. While they primarily serve as scopes, they can also be used
as hash tables, and sandboxing expression evaluation. Though R is lexically
scoped, ad-hoc lookup strategies can be implemented by accessing arbitrary
caller environments. The lexical scope of a function can be changed, a technique
often used for designing custom object-oriented systems.

\section{Analysis Infrastructure}
In this section, we describe the analysis infrastructure. It performs three
high-level tasks: assembling executable programs from R packages, generating
execution traces using a tracer, and post-processing the traces to generate
graphs and statistics. The entire pipeline is managed by a Makefile that invokes
R scripts for each step. Trace collection and analysis steps are parallelized
using GNU Parallel~\cite{gnuparallel}. The evaluation has been performed on a
dedicated analysis machine featuring an Intel Skylake CPU with 72 processors and
256 GB of RAM, and running Ubuntu 18.04 on a 5.4.0-73-generic Linux kernel. For
reproducibility, the infrastructure is installed in a container, based on Debian
10.9, and executed on the Docker runtime 20.10.5, build 55c4c88.

\subsection{Assembling Corpus}
The corpus of executable programs is assembled from R packages hosted on CRAN,
the official R package repository. Our scripts mirror CRAN on the analysis
server and install its packages. Another script invokes the R APIs that
locate and extract examples, tests, and vignettes from these packages. These
programs are then prepared for tracing by wrapping them in a call to the tracer.
Another set of scripts computes metadata such as lines of code from the
installed packages and extracted corpus.

\subsection{Generating Execution Traces}
Execution traces are generated using \envtracer, a dynamic analyzer built on top
of \rdyntrace. \rdyntrace is a modified GNU R virtual machine version
4.0.2~\cite{oopsla19b} that raises events during program execution. Callbacks
attached to these events receive relevant R objects at that point of execution.
\envtracer uses these callbacks to collect execution information associated with
environments. The events used by \envtracer include function entry and exit,
eval entry and exit, object allocation and deallocation, package loading and
attaching, variable lookup, assignment, and removal, subassignment, subsetting,
and attribute setting. On tracing entry, \envtracer initializes the tracing
state. When the program is about to exit \envtracer stores the traces in a
tabular format for post-processing. While the setup is conceptually simple, the
details are complex, and, affect scalability if not handled correctly. To handle
the subtleties of R, \envtracer maintains models of concrete R objects, such as
environments, functions, calls, and frames on the call stack. Model objects have
unique identities, whereas R objects are identified by their memory address, and
the garbage collector can reuse these. \envtracer takes care memory management
for model objects and provides efficient indexing. \envtracer heuristically
constructs names of model functions. The model stack updates itself
appropriately in response to longjump used by R for non-local returns.
Furthermore, \envtracer extends these models with custom fields which are
updated in response to \rdyntrace events for collecting data related to this
paper.

\subsection{Post-processing}
In the post-processing step, the execution traces are analyzed to gather
insights about the use of environments. \envtracer gathers 681GB of data from
the corpus. Scale is the major challenge. We use a custom map-reduce style
analysis to process this data. First, in the \textit{reduce} phase, the
individual execution traces are partially summarized in parallel to generate
smaller data tables per program, per analysis. This is the most expensive step
and it reduces the data size to XXX GB. Second, in the \textit{combine} phase,
these tables are concatenated into a single table per analysis. Third, in the
\textit{summarize} phase, final summaries are computed from the concatenated
tables. At this point, the data occupies only XXXKB. Finally, in the
\textit{report} phase, graphs and tables are generated from these summaries
using R Markdown notebooks\cite{rmdpkg, rmdguide, rmdcookbook}.

\section{Corpus of R Programs}

For this study, we assembled a corpus of 100 most widely used packages from
CRAN~\cite{ligges2017}, based on the number of client packages. These packages
together have 11,786 clients. Package \ggplot has the highest number of clients,
2,320, and package \vctrs has the fewest, 108. These packages contribute 481.5K
lines of R code and 1M lines of native code. During execution, these 100
packages call functions from 186 other packages, so our evaluation also includes
them. These extra packages have 478.2K lines of R code and 1.1M lines of native
code.


\begin{table}[!h]
  \vspace{-3mm}
  \small
  \centering
  \caption{Corpus}\label{table:corpus}
  \vspace{-3mm}
  \begin{tabular}{lrrr}
    \toprule
    &\bf Tests&\bf Examples&\bf Vignettes\\
    \midrule
    {Scripts}&1.9K&5.0K&187.0\\
    \midrule
    {LOC}&136.7K&55.2K&13.9K\\
    \bottomrule
  \end{tabular}
\end{table}

CRAN packages come equipped with runnable code in the form of tests, examples,
and long-form examples called vignettes. These programs are extracted as
independently executable scripts for evaluation by the \experimentr library.
Experiments demonstrate the use of a package's functions, and vignettes
illustrate a package's functionality with a larger example, typically using data
supplied with the package. Table~\ref{table:corpus} presents the number and size
of these scripts. Overall, there are 6.9K scripts with 205.8K lines of code.

The 286 corpus packages have 44.3K top-level functions, of which, 18.7K
functions are exercised by the extracted scripts. From the un-exercised 25.6K
functions, the majority, 17.2K, belong to transitively included packages, and,
8.4K belong to the initially selected 100 packages. Since the executable scripts
are extracted from 100 packages, they don't provide good coverage for the
transitively included 186 packages.

Table~\ref{table:fundist} presents the distribution of exercised functions
across these packages. We observe that 171 packages have 25 functions or less.
There are few large packages; 8 packages have more than 500 functions.

\begin{table}[!h]
  \vspace{-2mm}
  \small
  \caption{Package Size} \label{table:packsize}
  \centering
  \begin{tabular}{lr}
    \toprule
    \bf Functions&\bf Packages\\
    \midrule
    1--25&169\\
    26--50&40\\
    51--100&17\\
    101--150&14\\
    151--200&11\\
    201--250&15\\
    \bottomrule
  \end{tabular}
  \quad
  \begin{tabular}{lr}
    \toprule
    \bf Functions&\bf Packages\\
    \midrule
    251--300&4\\
    301--400&6\\
    401--500&2\\
    501--600&3\\
    601--700&0\\
    701--800&3\\
    \bottomrule
  \end{tabular}
\end{table}

We observed 42.1M calls to these functions. Figure~\ref{fig:calldist} shows the
distribution of calls. 52.9\% functions are called more than ten times. 14.3\%
functions are called only once, leading to low coverage.

\begin{figure}[!h]
  \centering
  \input{graphs/call_dist.tex}
  \caption{Call Distribution}
  \label{fig:calldist}
\end{figure}

These functions have a total of 67,225 parameter positions.
Figure~\ref{fig:paramdist} shows the distribution of parameter positions.
3.0\% functions have 0 parameters, 22.4\% have 1, and 5.0\% have over
10. There are 4 functions with over 50 parameters that come from 3 packages. Of
those, \texttt{ggplot2::theme} has the highest, 95 parameters.

\begin{figure}[!h]
  \centering
  \input{graphs/param_dist.tex}
  \caption{Parameter Distribution}
  \label{fig:paramdist}
\end{figure}

\section{Analyzing Environment Usage Patterns}

\subsection{Life Cycle of Environments}
In our corpus, we observe the creation of 1.2 B environments, which makes them
the second most widely allocated objects. Table~\ref{table:object_count_dist}
shows the distribution of R objects for comparison. Promises are the most widely
allocated objects, which is not surprising~\cite{oopsla19b}. Vectors of logicals
and characters (string) are more frequently allocated compared to that of
integers, reals, and raw (bytes). Language objects, i.e, first-class
expressions, are used for metaprogramming. Lists are heterogeneous vectors.
Other objects such as S4, externalptr, etc. are rare.

\begin{table}
  \vspace{-3mm}
  \small
  \caption{Object Counts} \label{table:object_count_dist}
  \centering
  \begin{tabular}{lr}
    \toprule
    \textbf{Type}&\textbf{Count}\\
    \midrule
    Promise&2.8B\\
    Environment&1.2B\\
    Logical&1.0B\\
    Character&929.9M\\
    Language&483.9M\\
    Integer&453.5M\\
    \bottomrule
  \end{tabular}
  \begin{tabular}{lr}
    \toprule
    \textbf{Type}&\textbf{Count}\\
    \midrule
    List&159.3M\\
    Closure&114.0M\\
    Real&113.4M\\
    Symbol&73.5M\\
    Raw&46.4M\\
    Other&15.2M\\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Where do environments come from?} The distribution of environments by
source is presented in Table~\ref{table:env_source}. The columns of this table
are to be read as follows. \emph{Core} represents the GNU R implementation and
its 16 packages: \code{base}, \code{compiler}, \code{datasets},
\code{grDevices}, \code{graphics}, \code{grid}, \code{methods}, \code{parallel},
\code{profile}, \code{splines}, \code{stats}, \code{stats4}, \code{tcltk},
\code{tools}, \code{translations}, and \code{utils}. \emph{User} represents CRAN
packages. \emph{Native} represents environment creation using the C APIs
\code{allocSExp}, \code{Rf_NewEnvironment}, and \code{Rf_NewHashedEnv}. Only
\code{allocSexp} is exported for use by external packages. \emph{R} represents
environment creation using \newEnv. 904.4K (0.08\%) environments were created
outside of the code being traced; hence they are ignored from the rest of the
discussion. We believe that most of these are environments created during lazy
loading of core R packges (which are loaded by default).

The R core is responsible for 99.89\% of the environments, dominated by
\emph{Native} . User packages are responsible for 0.03\% of the environments,
with twice as many from \emph{R} as \emph{Native}.

\begin{table}[!h]
  \vspace{-3mm}
  \small
  \centering
  \caption{Environment Source}\label{table:env_source}
  \vspace{-3mm}
  \begin{tabular}{llrr}
    \toprule
    \multirow{2}{*}{Core}  & \multicolumn{1}{l}{Native} & \multicolumn{1}{r}{1.2B} & \multicolumn{1}{r}{99.62\%}\\
                           & \multicolumn{1}{l}{R}     & \multicolumn{1}{r}{3.1M} & \multicolumn{1}{r}{0.27\%}\\
    \midrule
    \multirow{2}{*}{User}  & \multicolumn{1}{l}{Native} & \multicolumn{1}{r}{154.9K} & \multicolumn{1}{r}{0.01\%}\\
                           & \multicolumn{1}{l}{R}      & \multicolumn{1}{r}{240.4K} & \multicolumn{1}{r}{0.02\%}\\
    \bottomrule
  \end{tabular}
\end{table}


\emph{Core}, \emph{Native} environments: 99.7\% of environments in this category
are used for function calls, 344.7K are created for package loading and package
namespaces, 2.8M are created by the \code{methods} package for S4
object-oriented system, 165.5K by the \code{base} package for dynamic evaluation
using \code{eval}, 145.8K by \code{base} package for substitute.

\emph{Core}, \emph{R} environments: 94.1\% of these environments are created by
\code{base}, and 5.3\% by \code{methods} for the S4 object-oriented system. The
\code{base} package contribution comes from an internal function,
\code{lazyLoadDBexec}, used for loading package code and processed help files
from a binary database.

\emph{User} environments: These environments come from many packages and are
used for a variety of purposes such as hash tables, objects for custom OOP
systems, sandboxing, etc.

Overall, the environments can be divided into three categories as shown below in
table~\ref{table:env_category}.

\begin{table}
  \vspace{-3mm}
  \small
  \caption{Environment Source} \label{table:env_category}
  \centering
  \begin{tabular}{l|rr}
    \toprule
    \textbf{Source}&\textbf{Count}&\textbf{Percentage}\\
    \midrule
    Call&1.2B&99.32\%\\
    Explicit&3.7M&0.33\%\\
    Package&3.3M&0.28\%\\
    \bottomrule
  \end{tabular}
\end{table}

\section{Call Environments}

%% This is locked. I am working on it - Aviral

Of the 1.2 B call environments, only 20.9M call environments register any
events. Out of those 299.24K call environments outlive the frame that create
them. We present the sequence of events for the two kinds of call environments
separately.

\subsection{Normal Call Environments}

Table~\ref{table:call_env_seq} presents the event set for call environments that
don't escape. The top four sequences correspond to 98.4\% of the environments.
The events of interest are: \texttt{A} for read, write and remove, \texttt{V}
for environments used for evaluating code , \texttt{S} for substitute,
\texttt{X} corresponds to environment extraction using \code{parent.frame},
\code{sys.frame} or \code{sys.frames}.

\begin{table}[!h]
  \vspace{-3mm}
  \small
  \caption{Call Environment Sequence} \label{table:call_env_seq}
  \centering
  \begin{tabular}{lrr}
    \toprule
    \textbf{Event}&\textbf{\#}&\textbf{Cum. \%}\\
    \midrule
    \texttt{S}&9.8M&46.6\%\\
    \texttt{A, X}&8.3M&86.3\%\\
    \texttt{A, V, X}&2.2M&96.9\%\\
    \texttt{A, S, V, X}&312.6K&98.4\%\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{itemize}
\item[\textbf{S}:] This event happens in functions that use \code{substitute} on
  call's environment. 91\% of these cases originate from calls to \base package
  functions \code{::}, \code{:::}, \code{match.arg}, \code{delayedAssign}, and
  \code{evalq}. Expression \code{ns::sym} looks up the value of exported binding
  \code{sym} in namespace \code{ns}. \code{:::} allows lookup of private
  bindings. They uses substitute to access the symbol and namespace names,
  convert them to strings, and use \code{get} to perform the actual lookup. The
  \code{evalq} function is a composition of \code{quote} and \code{eval}. It
  uses substitute to extract the expression AST for evaluation in a custom
  environment. The expression \code{delayedAssign(x, expr, eval_env,
    assign_env)} binds \code{x} to a promise containing the unevaluated
  expression \code{expr} in \code{assign_env}. The expression itself is
  evaluated in \code{eval_env}. The extract the expression AST, this function
  uses \code{substitute}. The \code{match.arg} function matches the argument
  text against a specified list of choices.

\item[\textbf{X, A}:] These events happen to function environments whose environment
  is extracted and used for accessing or modifying bindings. An example is the use
  of \code{delayedAssign} by \code{base::registerS3methods::assignWrapped} which
  uses \code{parent.frame} to access caller environment for evaluating promise
  code. Similarly, \code{withr::set_envvar} calls \code{base::match.arg} which
  uses the parent frame for matching arguments. The \code{rlang::env_get} function
  looks up variables in parent's environment, extracted using \code{parent.frame}.

\item[\textbf{X, V, A}:] These events happens when an environment is extracted
  and used for evaluating expressions. The use of \code{glue::glue} function by
  \code{waldo::path_attr} is one such example. The \code{glue::glue} function
  performs string interpolation by evaluating R code embedded in curly braces in
  the string. It extracts the caller's environment using \code{parent.frame},
  evaluates these embedded code blocks, and replaces them with their value to
  obtain the interpolated string. Another source of these events is the use of
  \code{do.call} function, used by the \code{base::order} function. This
  function constructs a call expression with the supplied function name and
  arguments and evaluates it in the caller's environment, extracted using
  \code{parent.frame}.

\item[\textbf{X, S, V, A}] These events happen when environment is used for
  substitute as well as for evaluating expressions. This particularly happens
  when \code{match.arg} is used to match an argument against a set of options
  without specifying the set. In this case, \code{match.arg} uses
  \code{substitute} to get the argument name, reflectively accesses its default
  value expression from the parent environment, and evaluates it to get the set
  of acceptable options. The \code{match.arg} function is used in this form in
  the \code{base::textConnection} function for matching string encoding. Another
  example is the \code{glue::glue_data} function. This function forms the core
  of the \code{glue::glue} function, doing the actual interpolation. It uses
  substitute to access the inputs, which could be unnamed strings to be
  interpolated, or named arguments to be made available for substitution. Then,
  it evaluates them using \code{eval} which extracts the environment using
  \code{parent.frame} for evaluation.
\end{itemize}


\subsection{Escaped Call Environments}


%% Lock ends here

\section{Explicit Environments}
In this section, we discuss explicit environment creation using the \newEnv R
function and native code. 3.4M of these environments come from core and 395.2K
from user packages.

\subsubsection{Core Explicit Environments}

There are 9 packages responsible for all the explicit environments from
\emph{Core}. Table~\ref{table:core_explicit_pack} shows the number of
environments created by them. \code{methods} and \code{base} alone contribute to
99\% of the environments. The \code{methods} package implements the S4 OO system
and the \code{base} package exports the basic builtin functions of R.

\begin{table}[!h]
  \vspace{-3mm}
  \small
  \caption{Core Explicit Environment Packages} \label{table:core_explicit_pack}
  \centering
  \begin{tabular}{lrr}
    \toprule
    \textbf{Package}&\textbf{\#}&\textbf{Cu. \%}\\
    \midrule
    \code{methods}&3.0M&89.2\%\\
    \code{base}&329.9K&99.0\%\\
    \code{grid}&15.7K&99.5\%\\
    \code{grDevices}&10.7K&99.8\%\\
    \code{stats}&2.7K&99.9\%\\
    \code{compiler}&2.4K&100.0\%\\
    \code{parallel}&610.0&100.0\%\\
    \code{tools}&217.0&100.0\%\\
    \code{utils}&7.0&100.0\%\\
    \bottomrule
  \end{tabular}
\end{table}

The explicit environments in these 9 packages originate from 60 functions.
Table~\ref{table:core_explicit_fun} shows the top 6 functions. These functions
alone contribute to 98\% of all the explicit environments in \emph{Core}. They
belong to \code{methods} and \code{base} packages.

\begin{table}[!h]
  \vspace{-3mm}
  \small
  \caption{Core Explicit Environment Functions} \label{table:core_explicit_fun}
  \centering
  \begin{tabular}{lrr}
    \toprule
    \textbf{Function}&\textbf{\#}&\textbf{Cum. \%}\\
    \midrule
    \code{methods::new}&2.8M&84.3\%\\
    \code{base::eval}&165.5K&89.2\%\\
    \code{base::substitute}&145.8K&93.5\%\\
    \code{methods::.mlistAddToTable}&50.2K&95.0\%\\
    \code{methods::.resetInheritedMethods}&50.2K&96.5\%\\
    \code{methods::makeGeneric}&50.2K&98.0\%\\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Life-cycles}
We can characterize the life-cycle of these environments by summarizing the set
of events that affect them. Table~\ref{table:core_explicit_env_seq} shows the
top 6 event sets. The events of interest are: \texttt{A} for read, write and
remove, \texttt{V} for environments used for evaluating code, \texttt{L} for
locking the environment or its bindings, \texttt{!} for setting this environment
as the parent of another environment or lexical scope of a function, and
\texttt{Z} for modifying this environment's parent environment.

\begin{table}[!h]
  \vspace{-3mm}
  \small
  \caption{Core Explicit Environment Sequence} \label{table:core_explicit_env_seq}
  \centering
  \begin{tabular}{lrr}
    \toprule
    \textbf{Event}&\textbf{\#}&\textbf{Cum. \%}\\
    \midrule
    \texttt{A}&3.0M&88.4\%\\
    \texttt{A, V}&165.6K&93.4\%\\
    \texttt{S}&145.8K&97.7\%\\
    \texttt{A, Z, !}&50.2K&99.2\%\\
    \texttt{A, L, !}&12.1K&99.6\%\\
%    \texttt{A, @}&5.4K&99.7\%\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{itemize}
\item[\textbf{A}:] This is the most common pattern, and it occurs in many
  functions. The most common example is the \code{new} function of the methods
  object used for creating S4 objects. Another example is the grid package that
  uses explicit environments to create viewport objects and key their children
  by name. The \code{parallel::addClusterOptions} function uses an environment
  to store options about the cluster for parallel execution such as port number,
  timeout, and R path.
\item[\textbf{A, V}:] This pattern represents environments created by the
  \code{base::eval} and \code{base::evalq} functions. The default behavior of
  these functions is to evaluate an expression in the supplied environment.
  However, if a list of named elements is supplied instead of an environment, it
  is internally converted into an environment.
\item[\textbf{S}:] This pattern comes from the \code{base::substitute} function.
  This function is used for substituting symbols with expressions in ASTs. The
  substitutions are read either from an environment, or a list. If a list is
  supplied, it is converted into an environment internally.
\item[\textbf{A, Z, !}:] This patterns comes from the methods package's
  \code{makeGeneric} function. In the process of converting a function
  definition to a generic function, it creates a new environment, assigns the
  field \code{".Generic"} to the name of the generic method, sets its parent as
  the lexical scope of the function (\texttt{Z}), and finally, sets the new
  environment as the lexical scope of the function (\texttt{!}).
\item[\textbf{A, L, !}:] These event s happen in S4 objects. Their underlying
  data object consists of an environment with a reference \code{self} to the
  object itself. This binding is locked to prevent modification.
%\item[\textbf{A, @}:] This set occurs in \code{base} package's srcfilecopy and
%  srcfilealias functions. These functions are used for source code references,
%  \ie, with references to code in text files. They create a new environment, set
%  the filename and source code location information, and add the class
%  attributes \code{"srcfilealis"}, \code{"srcfilecopy"}, and \code{"srcfile"}.
\end{itemize}



\subsubsection{User Explicit Environments}
There are 55 packages responsible for all the explicit environments from
\emph{User}. Table~\ref{table:user_explicit_pack} shows the number of
environments created by the top 14 packages. These packages alone account for
98.9\% of all the environments in this category. The \code{vctrs} package
provides tools for type-coercion and size-recycling of R vectors. The
\code{rlang} package provides a consistent API to work with R objects and
exposes an evaluation mechanism used by the ``tidyverse'' packages for building
DSLs. \code{R6} implements a single-inheritance object-oriented system.
\code{codetools} implements code analysis for the R compiler. \code{ggplot2} is
a popular plotting library. \code{testthat} is widely used for testing R code.
Finally, \code{dplyr} implements a DSL for database style queries on data
frames.

\begin{table}[!h]
  \vspace{-3mm}
  \small
  \caption{User Explicit Environment Packages} \label{table:user_explicit_pack}
  \centering
  \begin{tabular}{lrr}
    \toprule
    \textbf{Package}&\textbf{\#}&\textbf{Cu. \%}\\
    \midrule
    \code{vctrs}&142.9K&36.2\%\\
    \code{rlang}&75.2K&55.2\%\\
    \code{R6}&74.1K&73.9\%\\
    \code{codetools}&39.2K&83.8\%\\
    \code{ggplot2}&24.3K&90.0\%\\
    \code{testthat}&9.1K&92.3\%\\
    \code{dplyr}&8.3K&94.4\%\\
    \bottomrule
  \end{tabular}
  \begin{tabular}{lrr}
    \toprule
    \textbf{Package}&\textbf{\#}&\textbf{Cu. \%}\\
    \midrule
    \code{magrittr}&6.1K&95.9\%\\
    \code{ps}&5.3K&97.3\%\\
    \code{forecast}&1.5K&97.6\%\\
    \code{data.table}&1.5K&98.0\%\\
    \code{igraph}&1.4K&98.4\%\\
    \code{plyr}&1.2K&98.7\%\\
    \code{cli}&846.0&98.9\%\\
    \bottomrule
  \end{tabular}
\end{table}

The explicit environments in these 55 packages originate from 322 functions.
Table~\ref{table:user_explicit_fun} shows the top ten functions. These functions
alone contribute to 65.1\% of all the explicit environments in \emph{User}.
These functions belong to 5 packages: \code{R6}, \code{vctrs}, \code{codetools},
\code{ggplot2}, and \code{rlang}.

\begin{table}[!h]
  \vspace{-3mm}
  \small
  \caption{User Explicit Environment Functions} \label{table:user_explicit_fun}
  \centering
  \begin{tabular}{lrr}
    \toprule
    \textbf{Function}&\textbf{\#}&\textbf{Cum. \%}\\
    \midrule
    \code{R6::generator_funs::new}&63.4K&16.0\%\\
    \code{vctrs::vec_c}&55.7K&30.1\%\\
    \code{codetools::mkHash}&31.3K&38.0\%\\
    \code{ggplot2::ggproto}&24.3K&44.2\%\\
    \code{rlang::eval_tidy}&18.1K&48.8\%\\
    \code{vctrs::vec_slice}&16.5K&52.9\%\\
    \code{rlang::new_data_mask}&13.8K&56.4\%\\
    \code{vctrs::vec_cast_common}&12.8K&59.7\%\\
    \code{vctrs::vec_as_names}&10.7K&62.4\%\\
    \code{R6::create_super_env}&10.6K&65.1\%\\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{What are environment life-cycles?}
Table~\ref{table:user_explicit_env_seq} shows the top 7 event sets, which
providing insights about 96.5\% of these environments. The event \texttt{@} is
used for setting attributes; the rest of the events have the same meaning as
before.

\begin{table}[!h]
  \vspace{-3mm}
  \small
  \caption{User Explicit Environment Sequence} \label{table:user_explicit_env_seq}
  \centering
  \begin{tabular}{lrr}
    \toprule
    \textbf{Events}&\textbf{\#}&\textbf{Cum. \%}\\
    \midrule
    \texttt{A, V}&154.0K&39.0\%\\
    \texttt{A}&102.8K&65.0\%\\
    \texttt{A, !}&43.8K&76.1\%\\
    \texttt{A, @}&38.9K&85.9\%\\
    \texttt{A, L}&30.4K&93.6\%\\
    \texttt{A, L, @}&8.3K&95.7\%\\
    \texttt{A, @, !}&3.2K&96.5\%\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{itemize}
\item[\textbf{A, V}:] This set accounts for the majority of environments. It is
  observed in 36 packages. These environments are created for custom evaluation
  strategies, \ie, for evaluating expressions with custom bindings in the scope.
  For example, \code{rlang::eval_tidy} is an an alternative to R's \code{eval}
  which provides support for evaluating ``quosures'', that are bundles of code
  and environment. On package load, \code{rlang} creates three environments from
  native code for use by its functions for evaluation in the context of a data
  frame. Another example is the \code{vctrs::vec_c} function which is
  alternative to R's \code{c} function for building a vector of values. It uses
  an explicit environment under the hood for repairing the names of the vector
  elements. The \code{testthat} testing library uses custom environment for
  evaluating testing code.

\item[\textbf{A}:] This pattern represents environments that are used as hash
  tables and package state. The \code{codetools} package provides facilities for
  analysis of R code. The \code{codetools::mkHash} function creates an
  environment for use as a hash table to store intermediate static analysis
  information. Another example is the \code{ps} package that provides facilities
  for handling system processes. It creates an environment on package load and
  initializes it with error codes and socket types. The \code{iterators} package
  uses environments as dynamic state of iterator objects.

\item[\textbf{A, !}:] This pattern represents environments that are set as
  parents of other environments or functions. This is dominated by \code{R.oo}
  and \code{R6} packages that implement object oriented systems. They create new
  environments and set them as lexical scopes of object methods. The
  \code{foreach} package provides iteration constructs that can execute code in
  sequence or parallel. The \code{foreach::\%do\%} function creates a new
  environment, assigns a marker, and sets it as the lexical scope of the
  function which uses the marker to decide whether to execute the code in
  parallel.

\item[\textbf{A, @}:] This pattern is used by packages to create custom objects,
  which can be used for dispatch based on the class attribute of the
  environments. \code{ggplot2} library implements \code{ggproto}, a prototype
  based OO system. The \code{ggproto} objects are explicit envivronments with
  \code{``ggproto''} class attribute. The \code{XML} package creates an environment
  to store a tree of nodes and assigns it a class attribute. the \code{xts}
  package creates a plot environment with plotting environments and sets an
  attribute on it.

\item[\textbf{A, L}:] This pattern is used by R6 to instantiate objects. The
  private bindings are locked in the object environment to prevent
  any modification. Many calls to \code{lockBinding} also originate form
  \code{data.table} which uses a custom environment to store intermeidate state
  for implementing dataframe indexing.

\item[\textbf{A, L, @}] The \code{later} and \code{R6} packages are responsible
  for this sequence. The \code{later} package use environments as handles for
  event loop objects. These objects contain the id of the loop, which is locked
  to prevent modifcation. The environments are assigned the class,
  \code{``event_loop''}. Similar to the previous sequence, the \code{R6} object
  locks the public bindings of an instantiated object, and also sets the class
  attribute.

\item[\textbf{A, @, !}] This patterns comes from the \code{plyr} package. It
  creates an environment with attribute \code{``idf''} for representing
  immutable data frames. It also assigns getter functions to this environment to
  access the columns of the data frame, and sets their environment to be the
  environment itself to ensure that lookup happens in the correct scope. This
  also occurs in \code{R6} when a class environments is set as the parent
  environment of a subclass environment.
\end{itemize}
\noindent

\paragraph{Formula}
Only 597 of these environments were used for formula construction. 389 of these
environments were created by testthat for code testing, implying that the code
being tested created a formula. The \code{survival} package creates explicit
environments for use in formulas. We observe 22 environments created by
\code{survival::coxph} and \code{survival::model.frame.coxph} to be used for
formula construction, as shown below.

\begin{lstlisting}
coxenv <- new.env(parent= environment(formula))
assign("tt", function(x) x, envir=coxenv)
environment(tform$formula) <- coxenv
\end{lstlisting}



\paragraph{Eval}
162K (41\%) of the explicit environments are used for dynamic code evaluation.
These environments come from 33 packages. 88.2\% of these environments come from
the \code{vctrs} package. Four packages, \code{vctrs}, \code{testthat},
\code{magrittr}, and \code{rlang} together contribute 98.2\% of these
environments.

\paragraph{Class Attributes}
50.8K (12.9\%) of the environments have a class attribute.
Table~\ref{table:explicit_env_attr} presents the class attributes attached to
environments by frequency and the package from which the attributes originate.
\code{ggplot2} alone accounts for 47.8\% of environments, owing to the
\code{ggproto} object system. \code{ggplot2}, \code{rlang}, \code{R6}, and
\code{plyr} account for 99.2\% of the environments with attributes.
\begin{table}[!h]
  \vspace{-3mm}
  \small
  \caption{Environment Attributes} \label{table:explicit_env_attr}
  \centering
  \begin{tabular}{llrr}
    \toprule
    \textbf{Package}&\textbf{Attributes}&\textbf{\#}&\textbf{Cum. \%}\\
    \midrule
    \texttt{ggplot2}&\texttt{ggproto gg}&24.3K&47.8\%\\
    \texttt{rlang}&\texttt{rlang\_ctxt\_pronoun}&12.1K&71.5\%\\
    \texttt{R6}&\texttt{R6}&9.2K&89.5\%\\
    \texttt{rlang}&\texttt{r6lite}&3.7K&96.8\%\\
    \texttt{plyr}&\texttt{idf environment}&1.2K&99.2\%\\
    \texttt{later}&\texttt{event\_loop}&279.0&99.7\%\\
    \texttt{R6}&\texttt{R6ClassGenerator}&113.0&100.0\%\\
    \texttt{shiny}&\texttt{session\_proxy}&12.0&100.0\%\\
    \texttt{XML}&\texttt{XMLHashTree XMLAbstractDocument}&10.0&100.0\%\\
    \texttt{xts}&\texttt{replot\_xts environment}&2.0&100.0\%\\
    \bottomrule
  \end{tabular}
\end{table}


\section{Package Environments}
We observe 3.3M environments related to packages and namespaces. The package
loading mechanism alone accounts for 2.9M of these environments, the remaining
representing packages and namespaces. 2.3M of the environments come from a
single \base package function, \lazyLoadDBexec, used only internally. This
function is responsible for loading a package's code from a binary file and also
for loading processed help file data. 481K functions come from the
\code{loadNamespace} function of the \code{base} package. This function is used
for loading package namespaces. A few environments are created internally by the
interpreter to store a package's native functions exported for use by other
packages. The final source of these environments is the sandbox created by R's
\code{base::local} function to initiate the loading of package. We ignore the
environments associated with packages and namespaces from the rest of the
discussion.


\bibliography{bib/jv,bib/aviral}



\end{document}

% TODO
% - environment source
%            C   new.env
% - base
% - library
%
% environment class
% -
